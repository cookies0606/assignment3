import streamlit as st
import os
import openai
import tempfile
import faiss
import numpy as np
from PyPDF2 import PdfReader
from sklearn.metrics.pairwise import cosine_similarity

# ì„¸ì…˜ ì´ˆê¸°í™”
if "index" not in st.session_state:
    st.session_state.index = None
if "docs" not in st.session_state:
    st.session_state.docs = []
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ChatPDF (No LangChain)", layout="wide")
st.title("ğŸ“„ ChatPDF (langchain ì—†ì´ êµ¬í˜„)")

# API í‚¤ ì…ë ¥
api_key = st.text_input("ğŸ”‘ OpenAI API Key ì…ë ¥", type="password", value=st.session_state.api_key)
if api_key:
    st.session_state.api_key = api_key
    openai.api_key = api_key

# Clear ë²„íŠ¼
if st.button("ğŸ§¹ Clear Vector Store"):
    st.session_state.index = None
    st.session_state.docs = []
    st.success("ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì™„ë£Œ!")

# PDF ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

# PDF â†’ í…ìŠ¤íŠ¸ â†’ ì²­í¬ ë¶„ë¦¬ â†’ ì„ë² ë”© + FAISS
def embed_texts(text_chunks):
    embeddings = []
    for chunk in text_chunks:
        response = openai.Embedding.create(
            model="text-embedding-ada-002",
            input=chunk
        )
        embedding = response['data'][0]['embedding']
        embeddings.append(np.array(embedding, dtype=np.float32))
    return embeddings

def split_text(text, max_tokens=500):
    sentences = text.split(". ")
    chunks, chunk = [], ""
    for sentence in sentences:
        if len(chunk) + len(sentence) < max_tokens:
            chunk += sentence + ". "
        else:
            chunks.append(chunk.strip())
            chunk = sentence + ". "
    if chunk:
        chunks.append(chunk.strip())
    return chunks

if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name

    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
    reader = PdfReader(tmp_path)
    raw_text = ""
    for page in reader.pages:
        raw_text += page.extract_text()

    # ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
    text_chunks = split_text(raw_text)
    st.session_state.docs = text_chunks

    # ì„ë² ë”© ë° FAISS ìƒ‰ì¸ êµ¬ì¶•
    embeddings = embed_texts(text_chunks)
    dimension = len(embeddings[0])
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings))
    st.session_state.index = index

    st.success("âœ… PDF ì²˜ë¦¬ ë° ì„ë² ë”© ì™„ë£Œ!")

# ì§ˆë¬¸ ì…ë ¥
query = st.text_input("â“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

# ì§ˆì˜ì‘ë‹µ ìˆ˜í–‰
if query and st.session_state.index:
    # ì¿¼ë¦¬ ì„ë² ë”©
    query_embedding = openai.Embedding.create(
        model="text-embedding-ada-002",
        input=query
    )["data"][0]["embedding"]
    query_vector = np.array(query_embedding, dtype=np.float32).reshape(1, -1)

    # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
    D, I = st.session_state.index.search(query_vector, k=3)
    retrieved_docs = [st.session_state.docs[i] for i in I[0]]

    context = "\n".join(retrieved_docs)
    prompt = f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:\n\n{context}\n\nì§ˆë¬¸: {query}\në‹µë³€:"
    
    # ChatGPTë¡œ ì§ˆë¬¸
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )
    answer = response["choices"][0]["message"]["content"]
    st.markdown(f"ğŸ“˜ **ë‹µë³€:** {answer}")
