import streamlit as st
import openai
from openai import OpenAI
import os

# íŒŒì¼ ì €ì¥ìš©
def save_file(uploaded_file):
    with open(uploaded_file.name, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return uploaded_file.name

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "assistant" not in st.session_state:
    st.session_state.assistant = None
if "thread" not in st.session_state:
    st.session_state.thread = None
if "vector_store" not in st.session_state:
    st.session_state.vector_store = None
if "client" not in st.session_state:
    st.session_state.client = None
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

# Streamlit UI
st.title("ğŸ“„ File Assistant ChatBot")
api_key = st.text_input("ğŸ”‘ OpenAI API Key", type="password", value=st.session_state.api_key)
if api_key:
    st.session_state.api_key = api_key
    st.session_state.client = OpenAI(api_key=api_key)

uploaded_file = st.file_uploader(" í…ìŠ¤íŠ¸ ë˜ëŠ” PDF íŒŒì¼ ì—…ë¡œë“œ", type=["txt", "pdf"])

if st.button("ğŸ§¹ Clear Vector Store"):
    st.session_state.vectorstore = None
    st.success("ë²¡í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ë²¡í„° ìŠ¤í† ì–´ + ì–´ì‹œìŠ¤í„´íŠ¸ ìƒì„±
if uploaded_file and st.button(" íŒŒì¼ ì—…ë¡œë“œ ë° ì±—ë´‡ ìƒì„±"):
    filename = save_file(uploaded_file)
    client = st.session_state.client

    # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    vector_store = client.vector_stores.create(name="chatfilestore")
    st.session_state.vector_store = vector_store
    st.session_state.vector_store_id = vector_store.id

    # íŒŒì¼ ì—…ë¡œë“œ ë° ì¸ë±ì‹±
    with open(filename, "rb") as f:
        client.vector_stores.file_batches.upload_and_poll(
            vector_store_id=vector_store.id,
            files=[f]
        )

    # ì–´ì‹œìŠ¤í„´íŠ¸ ìƒì„±
    assistant = client.beta.assistants.create(
        instructions="ì—…ë¡œë“œëœ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì¹œì ˆí•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”.",
        model="gpt-4o",  # ë˜ëŠ” "gpt-4o-mini"
        tools=[{"type": "file_search"}],
        tool_resources={
            "file_search": {
                "vector_store_ids": [vector_store.id]
            }
        }
    )
    st.session_state.assistant = assistant

    # ì“°ë ˆë“œ ìƒì„±
    st.session_state.thread = client.beta.threads.create()
    st.success("ì–´ì‹œìŠ¤í„´íŠ¸ ì¤€ë¹„ ì™„ë£Œ! ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”.")

# ì±— ì¸í„°í˜ì´ìŠ¤
if st.session_state.assistant and st.session_state.thread:
    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    if user_input:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            msg = st.session_state.client.beta.threads.messages.create(
                thread_id=st.session_state.thread.id,
                role="user",
                content=user_input
            )
            run = st.session_state.client.beta.threads.runs.create_and_poll(
                thread_id=st.session_state.thread.id,
                assistant_id=st.session_state.assistant.id
            )

            if run.status == "completed":
                messages = st.session_state.client.beta.threads.messages.list(
                    thread_id=st.session_state.thread.id
                )
                for m in reversed(messages.data):
                    if m.role == "assistant":
                        st.markdown(f" **Assistant:** {m.content[0].text.value}")
                        break
            else:
                st.error(f" Error: {run.status}")
