import streamlit as st
import openai
import tempfile

st.set_page_config(page_title="ChatPDF", page_icon="ğŸ“„")
st.title("ğŸ“„ Chat with PDF")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "vector_store_id" not in st.session_state:
    st.session_state.vector_store_id = None
if "pdf_file_id" not in st.session_state:
    st.session_state.pdf_file_id = None
if "assistant_id" not in st.session_state:
    st.session_state.assistant_id = None
if "thread_id" not in st.session_state:
    st.session_state.thread_id = None

# API í‚¤ ì…ë ¥
api_key = st.text_input("ğŸ”‘ OpenAI API Key", type="password", value=st.session_state.get("api_key", ""))
if api_key:
    st.session_state.api_key = api_key
    client = openai.OpenAI(api_key=api_key)
else:
    st.warning("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# PDF ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“ PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name

    with st.spinner("ğŸ“¤ PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            file = client.files.create(file=open(tmp_path, "rb"), purpose="assistants")

            vector_store = client.vector_stores.create(name="My PDF Store")
            client.vector_stores.file_batches.upload_and_poll(
                vector_store_id=vector_store.id,
                files=[file.id]
            )

            assistant = client.assistants.create(
                name="PDF Assistant",
                instructions="ë‹µë³€í•  ë•Œ ì—…ë¡œë“œëœ PDFë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.",
                tools=[{"type": "file_search"}],
                model="gpt-4-1106-preview",
                tool_resources={"file_search": {"vector_store_ids": [vector_store.id]}}
            )

            thread = client.threads.create()

            st.session_state.vector_store_id = vector_store.id
            st.session_state.pdf_file_id = file.id
            st.session_state.assistant_id = assistant.id
            st.session_state.thread_id = thread.id

            st.success("âœ… ë²¡í„° ìŠ¤í† ì–´ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”!")

        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

# Clear ë²„íŠ¼
if st.session_state.vector_store_id and st.button("ğŸ§¹ Clear Vector Store"):
    try:
        client.vector_stores.delete(st.session_state.vector_store_id)
        st.success("ğŸ—‘ï¸ Vector Store ì‚­ì œ ì™„ë£Œ")
        for key in ["vector_store_id", "pdf_file_id", "assistant_id", "thread_id"]:
            st.session_state[key] = None
    except Exception as e:
        st.error(f"âŒ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ì§ˆë¬¸ ë° ì‘ë‹µ
if st.session_state.vector_store_id:
    question = st.text_input("â“ PDFì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”")
    if question:
        with st.spinner("ğŸ¤– GPTê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                client.threads.messages.create(
                    thread_id=st.session_state.thread_id,
                    role="user",
                    content=question,
                    file_ids=[st.session_state.pdf_file_id]
                )

                run = client.threads.runs.create_and_poll(
                    thread_id=st.session_state.thread_id,
                    assistant_id=st.session_state.assistant_id
                )

                messages = client.threads.messages.list(thread_id=st.session_state.thread_id)
                for msg in reversed(messages.data):
                    if msg.role == "assistant":
                        st.markdown("### ğŸ¤– GPTì˜ ë‹µë³€")
                        st.write(msg.content[0].text.value)
                        break
            except Exception as e:
                st.error(f"âŒ ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
